#!/usr/bin/env ts-node

/**
 * Direct test of inference.net LLM with MCP tools
 */

import * as dotenv from 'dotenv';
dotenv.config();

import { HTTPMCPClient } from '../../src/mcp/http-mcp-client';
import { InferenceNetLLM } from '../../src/llm/inference-net-llm';

async function testInferenceNetDirect() {
    console.log('ðŸ§  Testing Inference.net LLM Direct Integration');
    console.log('='.repeat(60));

    try {
        // Initialize MCP client
        console.log('1. Initializing MCP client...');
        const mcpClient = new HTTPMCPClient('http://localhost:8000');
        await mcpClient.initialize();
        console.log('   âœ… MCP client connected to bridge');

        // Initialize inference.net LLM
        console.log('\n2. Initializing Inference.net LLM...');
        const inferenceLLM = new InferenceNetLLM({
            apiKey: process.env['INFERENCE_NET_KEY'] || '',
            model: 'meta-llama/llama-3.2-3b-instruct/fp-16',
            temperature: 0.1,
            maxTokens: 1000
        });
        console.log('   âœ… Inference.net LLM initialized');

        // Test 1: Direct LLM Query
        console.log('\n3. Testing Direct LLM Query...');
        const llmResponse = await inferenceLLM.invoke('What is 15 * 8 + 42 / 7? Please show your work step by step.');
        console.log('   ðŸ“¤ Query: What is 15 * 8 + 42 / 7? Show your work.');
        console.log('   ðŸ“¥ Response:', llmResponse.content);
        console.log('   âœ… Direct LLM query successful');

        // Test 2: LLM + Tool Integration
        console.log('\n4. Testing LLM + Tool Integration...');
        
        // Let LLM reason about tool selection
        const tools = mcpClient.getTools();
        const toolNames = tools.map(t => t.name).join(', ');
        
        const reasoningPrompt = `I need to calculate (25 * 4) + (100 / 5). 
        I have access to these tools: ${toolNames}.
        Which tool should I use and what parameters should I pass?`;
        
        const reasoningResponse = await inferenceLLM.invoke(reasoningPrompt);
        console.log('   ðŸ“¤ Reasoning Query:', reasoningPrompt);
        console.log('   ðŸ“¥ LLM Reasoning:', reasoningResponse.content);
        
        // Execute the calculation tool
        const calcResult = await mcpClient.executeTool('calculate', { expression: '(25 * 4) + (100 / 5)' });
        console.log('   ðŸ”§ Tool Execution Result:', calcResult);
        
        // Let LLM interpret the result
        const interpretationPrompt = `The calculation tool returned: ${JSON.stringify(calcResult)}. 
        Please explain what this result means and verify if it's correct.`;
        
        const interpretationResponse = await inferenceLLM.invoke(interpretationPrompt);
        console.log('   ðŸ“¤ Interpretation Query:', interpretationPrompt);
        console.log('   ðŸ“¥ LLM Interpretation:', interpretationResponse.content);
        console.log('   âœ… LLM + Tool integration successful');

        // Test 3: Complex Multi-step Task
        console.log('\n5. Testing Complex Multi-step Task...');
        
        // Step 1: Create todos
        const todoResult = await mcpClient.executeTool('create_todos', { 
            todos: ['Test inference.net LLM', 'Verify tool integration', 'Document results'] 
        });
        console.log('   ðŸ”§ Todo Creation Result:', todoResult);
        
        // Step 2: Calculate something
        const calcResult2 = await mcpClient.executeTool('calculate', { expression: '2^10' });
        console.log('   ðŸ”§ Calculation Result:', calcResult2);
        
        // Step 3: Let LLM coordinate and summarize
        const coordinationPrompt = `I just completed a multi-step task:
        1. Created todos: ${JSON.stringify(todoResult)}
        2. Calculated 2^10: ${JSON.stringify(calcResult2)}
        
        Please summarize what was accomplished and provide insights about the task execution.`;
        
        const coordinationResponse = await inferenceLLM.invoke(coordinationPrompt);
        console.log('   ðŸ“¤ Coordination Query:', coordinationPrompt);
        console.log('   ðŸ“¥ LLM Coordination:', coordinationResponse.content);
        console.log('   âœ… Complex multi-step task successful');

        // Test 4: Web Search + LLM Analysis
        console.log('\n6. Testing Web Search + LLM Analysis...');
        
        // Execute web search
        const webResult = await mcpClient.executeTool('search_web', { 
            query: 'TypeScript AI agent frameworks 2024', 
            max_results: 2 
        });
        console.log('   ðŸ”§ Web Search Result:', JSON.stringify(webResult).substring(0, 300) + '...');
        
        // Let LLM analyze the results
        const analysisPrompt = `I searched for "TypeScript AI agent frameworks 2024" and got these results: ${JSON.stringify(webResult).substring(0, 500)}...
        Please analyze the key findings and trends in TypeScript AI agent development.`;
        
        const analysisResponse = await inferenceLLM.invoke(analysisPrompt);
        console.log('   ðŸ“¤ Analysis Query:', analysisPrompt);
        console.log('   ðŸ“¥ LLM Analysis:', analysisResponse.content);
        console.log('   âœ… Web search + LLM analysis successful');

        // Summary
        console.log('\nâœ… All inference.net LLM integration tests completed!');
        console.log('ðŸŽ‰ Inference.net LLM is working perfectly with MCP tools');
        console.log('ðŸ§  Real LLM reasoning and tool coordination is functional');
        console.log('ðŸ”§ Multi-step workflows with real LLM are working');
        console.log('ðŸ“Š Complex task solving with LLM + tools is successful');
        
        return true;
    } catch (error) {
        console.error('âŒ Inference.net LLM test failed:', error);
        return false;
    }
}

if (require.main === module) {
    testInferenceNetDirect().then(success => {
        process.exit(success ? 0 : 1);
    });
}
